\documentclass{scrreprt}
\usepackage[x11names]{xcolor}	% colori
\usepackage{pgfplots}			% grafici
\usepackage{imakeidx}			% indice
\usepackage{amsfonts}			% font matematici	
\usepackage{amsthm}				% teoremi				
\usepackage{array}				% matrici
\usepackage{mdframed}			% cornici al testo
\usepackage{mathtools}			% matematica
\usepackage{hyperref}			% collegamenti ipertestuali per l'indice
\usepackage[italian]{babel}

\newcommand{\SectionBreak}{%
    %\vskip 0.5ex

    \nointerlineskip
    \moveright 0.125\textwidth \vbox{\hrule width0.75\textwidth}
    \nointerlineskip
    %\vskip 0.5ex
    \makeatletter
        %\@afterindenfalse%
    \makeatother

}

% Impostazioni grafici pgfplots, altrimenti si lamenta
\pgfplotsset{compat=1.18}

% Definizione dell'ambiente "Definizione"
\newtheorem{defn}{Definizione}
\newenvironment{definition}{\begin{mdframed}[backgroundcolor=Ivory2]\begin{defn}}{\end{defn}\end{mdframed}}

% Definizione dell'ambiente "Teorema"
\newtheorem{teorema}{Teorema}
\newenvironment{thm}{\begin{mdframed}[backgroundcolor=Ivory2]\begin{teorema}}{\end{teorema}\end{mdframed}}

% Definizione dell'ambiente "Dimostrazione"
\newtheorem{demnstrn}{Dimostrazione}
\newenvironment{dimostrazione}{\begin{mdframed}[backgroundcolor=LightCyan1]\begin{demnstrn}}{\end{demnstrn}\end{mdframed}}

% Solo le equazioni referenziate vengono numerate
% vedi https://tex.stackexchange.com/a/2602
\mathtoolsset{showonlyrefs}  


\author{F. Piazza}
\title{%
	Appunti di Analisi Matematica II \\
	\large corso della prof.ssa B.Noris \\
	Politecnico di Milano\\
	\bigskip
	\bigskip


	\begin{tikzpicture}
	\begin{axis}[axis line style={draw=none}, colormap/bluered]
	\pgfplotsset{ticks=none}
	 \addplot [domain=0:1, samples=100, color=black, thick] {x};
	% \addplot3[surf, samples=50, opacity=0.5, shader=interp] {x^2-y^2};
	\end{axis}
	\end{tikzpicture}
}


\begin{document}
\maketitle

\section*{}

Gli esami non finiscono mai, amico mio! Così è la vita. \medskip \\
\null\hfill- \textit{Denis Ivanovič Fonvizin}
	


\tableofcontents

\setcounter{chapter}{-1} % per evitare che il capitolo 1 venga numerato come 2
\chapter{Cenni di Analisi I e Algebra Lineare}
\section{Regole di integrazione e derivazione}


\section{Serie numeriche}

\section{Determinante di una matrice}

\chapter{Equazioni differenziali}
\section{Equazioni differenziali del 1° ordine}
\begin{definition}
	Una equazione differenziale o \emph{EDO} del 1° ordine è una relazione tra una funzione $y$ e la sua derivata $y'$ che può essere scritta come
	\begin{equation}
		y' = f(y)
	\end{equation}
	dove $f$ è una funzione continua su un intervallo $I\subseteq\mathbb{R}$.
\end{definition}

Esempi:
\begin{itemize}
	\item \emph{Tema d'esame gennaio 2021}\\$y' = t \sqrt{y_{(t^2)}+1}$ è in forma normale con $f(t,s) = t \sqrt{s^2+1}$. Il dominio di $f$ è $I = \mathbb{R} \times \mathbb{R} = \mathbb{R}^2$.
	\item $y'_{(t)} = \frac{1}{t}$ con $t>0$ diventa $f(t,s) = \frac{1}{t}$. \textbf{Oss:} $f$ non dipende esplicitamente da $s$. \\ Il dominio di $f$ è $\{(t,s) \in \mathbb{R}^2 : s\in\mathbb{R}, t\in\mathbb{R}^* \}$, dunque è diviso in due parti.
			Dovrò quindi risolvere la EDO separatamente nelle due regioni.
			$$ \left\{\begin{array}{lr} y'(0)=\frac{1}{t},	t>0 \Rightarrow y(t) = ln(t)+c\\ y'(0)=\frac{1}{t},	t<0 \Rightarrow y(t) = ln(-t)+c \end{array}\right. $$
\end{itemize}
\begin{definition}
	Si chiama \emph{integrale generale} l'insieme delle soluzioni.
\end{definition}
\begin{definition}
	Si chiama \emph{soluzione particolare} una specifica soluzione.
\end{definition}
\noindent{Una EDO del 1° ordine ha $\infty^1$, soluzioni, cioè avrà una costante arbitraria. In modo analogo, una EDO del 2° ordine avrà $\infty^2$ soluzioni, cioè avrà due costanti arbitrarie.}
Esempi:
\begin{itemize}
	\item integrale generale $ce^t$ con $c$ costante arbitraria. Esempi di soluzioni particolari: $e^t$, $2e^t$, $-e^t$.
	\item $z_{(t)} = -1 + arctan(t)$ con $t\in\mathbb{R}^*$. Esempio di soluzione: $z' = 0 + \frac{1}{1+t^2}$.
\end{itemize}
\textbf{Oss:} La EDO $y'_{(t)} = f(t,y_{(t)})$ è definita per $(t,y)\in dom(f)$

\subsection{Soluzioni costanti di EDO del 1° ordine}
\begin{definition}
	Una soluzione costante di una EDO del 1° ordine è una funzione $y(t)$ che sia soluzione.
\end{definition}
Quando $y(t)=c$ è soluzione? Sostituisco $c$ a $y$:
\begin{equation}
	y'(t) = f(t,y(t)) \forall t
\end{equation}

Quindi \underline{le soluzioni costanti sono} $y(t) = c$ \underline{con $c$ tale che} $f(t,c) = 0 \forall t$.\\

Esempi:
\begin{itemize}
	\item Eq. Logistica: $y'(t) = ky(t)-hy^2(t)$\\
			$f(t,y)=ky-hy^2$\\
			$f(t,c)= 0 \forall t$ \quad $ky-hy^2=0=y(k-hy)$\\
			Soluzioni costanti: $y=0$ o $y=\frac{k}{h}$
	\item $y'(t)=te^{y(t)}$ \quad $te^{y(t)}=0$ non ha soluzione.
\end{itemize}

\SectionBreak

\subsection{EDO a variabili separabili}
\begin{definition}
	Una EDO del 1° ordine è detta \emph{a variabili separabili} se è del tipo
	\begin{equation}
		y' = f(t)\cdot g(y(t))
	\end{equation}
	dove $f$ e $g$ sono funzioni continue su intervalli $J_1,J_2\subseteq\mathbb{R}$.
\end{definition}

\begin{center}

	%scrivi in grassetto "Esempio"
	\textbf{Esempio}
	$y'(t)=\frac{1}{t}$ $\; h(t)=\frac{1}{t}$ $\;j_1=(-\infty,0)U(0,\infty)=\mathbb{R}$-{0}
\end{center}



\SectionBreak
\newpage
\subsection{Problema di Cauchy}
\begin{definition}
	Data una EDO del 1° ordine $y'_{(t)} = f(t,y_{(t)})$ sia $(t_{0}, y_{0})$ dove la EDO è definita.
	Cioè $(t_{0},y_{0})\in dom(f)$ \\
	Si chiama \emph{problema di Cauchy} il problema di determinare $y : I\subseteq \mathbb{R} \to \mathbb{R}$ che soddisfa:
	$$ \left\{\begin{array}{lr}y'(t)=f(t,y(t)) \\ y(t_{0})=y_{0}\end{array}\right. $$
\end{definition}
Nota: il sistema ha una condizione perché è del 1° ordine. La condizione trova la soluzione particolare che passa per $(t_{0},y_{0})$.\\
\SectionBreak
\subsection{Come si risolve?}
Step:
\begin{enumerate}
	\item Trova l'integrale generale. ($\infty^1$ soluzioni dipendenti da 1 parametro)
	\item Impongo la condizione $y(t_{0})=y_{0}$ e la costante $c$
	\item Sostituisco $c$ in 1.
\end{enumerate}

\subsubsection{Esempi}
Aggiungi Esempi\\
\SectionBreak

\subsection{EDO 1° ordine lineari}
\begin{definition}
	Una EDO del 1° ordine lineare in forma normale è:\\
	\begin{equation}
		y'_{(t)} = a(t)y_{(t)} + b(t)
	\end{equation}
	dove $a$ e $b$ sono funzioni continue su un intervallo $J$ di $\mathbb{R}$.\\
	\textbf{N.B.} $J$ è il più grande intervallo di $\mathbb{R}$ tale che $a,b\in J$.\\
\end{definition}

\begin{definition}
	Si chiama EDO omogenea associata
	\begin{equation}
		y'_{(t)} = a(t)y_{(t)}\\
	\end{equation}
\end{definition}
Esempio:\\
Aggiungi esempi
\\
\SectionBreak
\subsection{Principio di sovrapposizione}
Sia $a: J\subseteq\mathbb{R} \to \mathbb{R}$ una funzione continua su $J$.\\L'applicazione $\mathcal{L}(y)=y'-a(t)\cdot y$ è lineare.\medskip\\
Più esplicitamente, dati $c_1,c_2 \in \mathbb{R}$:\\
$\mathcal{L}(c_1y_1+c_2y_2)=c_1\mathcal{L}(y_1)+c_2\mathcal{L}(y_2) \forall y_1,y_2$ funzioni derivabili.\medskip\\
Ancora più esplicitamente:
se $\mathcal{L}(y_1)=b_1$ cioè $y'_1=a(t)y_1+b_1$\\
se $\mathcal{L}(y_2)=b_2$ cioè $y'_2=a(t)y_2+b_2$\\
allora $\mathcal{L}(c_1y_1+c_2y_2)=c_1b_1+c_2b_2$ cioè $y'_{(t)}=a(t)(c_1y_1+c_2y_2)+c_1b_1+c_2b_2$\\
cioè $(c_1y_1+c_2y_2)'=a(t)(c_1y_1+c_2y_2)+c_1b_1+c_2b_2$\\
\textbf{Oss:} \begin{itemize}
	\item Prendo due soluzioni distinde della EDO 
    \item  $y'=a(t)y + b(t)$\\
\end{itemize}
\SectionBreak
\subsection{Esistenza e unicità globale di Cauchy}
Siano $J\subseteq\mathbb{R}$ intervallo e $a,b: J\to \mathbb{R}$ continue.\\
Per ogni $t_0\in J, y_0 \in \mathbb{R}$ il problema di Cauchy:
\begin{equation}
	\left\{\begin{array}{lr}y'(t)=a(t)y(t)+b(t) \\ y(t_0)=y_0\end{array}\right.
\end{equation}
ha una soluzione unica $y: J\to \mathbb{R}$ definita su $J$.\\
\textbf{Aggiungi parte in blu lezione 16/09/2022}\\

\SectionBreak

\subsection{Teorema Formula risolutiva per EDO lineari 1° ordine}
$a,b: J\subseteq\mathbb{R}\to\mathbb{R}$ \quad $y'(t) = a(t)y(t)+b(t)$\\
L'integrale generale è dato dalla formula:
\begin{equation}
	y(t)=e^{A(t)}+\left( \int e^{-A(x)}b(x)dx + c \right) \quad \forall c\in \mathbb{R}
\end{equation}
dove $A(t)$ è una primitiva di $a$.\\

\begin{dimostrazione}
\emph{\textbf{da sapere all'esame}}\\
\begin{itemize}
	\item Porto $ay$ sulla sinistra\\
			$y'-ay=b$
	\item Moltiplico l'equazione per $e^{-A}$\\
			$e^{-A}y'-e^{-A}ay=e^{-A}b$
	\item Riconosco\\
			$y'(t)e^{-A(t)}-a(t)y(t)e^{-A(t)}=\left(y(t)e^{-A(t)}\right)$\\
			Quindi la EDO iniziale si riscrive equivalentemente:\\
			$(ye^{-A})'=be^{-A}$
	\item Integro\\
			$y(t)e^{-A(t)}=\int be^{-A(t)}dt+c$
	\item Moltiplico tutto per $e^{A(t)}$\\
			$y(t)=e^{A(t)}\left(\int be^{-A(t)}dt+c\right)$
\end{itemize}
\end{dimostrazione}

\SectionBreak

\subsection{Equazione di Bernoulli}
\begin{definition}
	Si chiamano \emph{equazione di Bernoulli} le EDO del 1° ordine lineari di forma:\\
	\begin{equation}
		y'_{(t)} = k(t)y_{(t)} + h(t)y_{(t)}^\alpha \quad \forall \alpha \in \mathbb{R}\setminus \{0,1\}
	\end{equation}
	con $k,y: J\subseteq\mathbb{R}\to\mathbb{R}$ continue.
\end{definition}

\textbf{Premesse:}\\
\begin{enumerate}
	\item Per semplificare ci occupiamo solo di soluzioni $y \geq 0$
	\item nel caso $\alpha<1$ accadono fenomeni strani, però la tecnica risolutiva è comunque valida
\end{enumerate}

\noindent{Procedimento di risoluzione:}\\
\begin{enumerate}
	\item Cerchiamo le soluzioni costanti (c'è sempre almeno quella nulla)
	\item divido per $y^\alpha$\\
			$y'(t) = k(t)y(t) + h(t)$\\
			$y'(t) = k(t)y(t)^{1-\alpha} + h(t)$
	\item Pongo $z(t)=y(t)^{1-\alpha}$\\
			Quale è l'equazione soddisfatta da $z$?\\
			$z'(t)= \left(1-\alpha\right)\left[k(t)y(t)^{1-\alpha}+h(t)\right] $\\
			$z'(t)=\left(1-\alpha\right)k(t)z(t)+\left(1-\alpha\right)h(t)$\\
	\item Risolvo l'equazione lineare in $z$
	\item Torno alla variabile $y = z(t)^{\frac{1}{1-\alpha}}$
\end{enumerate}

\SectionBreak

\subsection{Equazione Logistica}
$y(t) = $ numero di individui infetti al tempo $t$\\
$y: J\subseteq\mathbb{R}^+\to\mathbb{R}^+$
\bigskip\\
\textbf{1° Modello: Malthus (inizio '800)}\\
Il tasso di crescita della popolazione è proporzionale alla popolazione stessa.\\
\begin{equation}
	y'(t) = ky(t)
\end{equation}
dove $k\in\mathbb{R}^+$ è la \emph{tasso di crescita} e $k$ è il coefficiente di proporzionalità, dato dalla differenza tra tasso di natalità e tasso di mortalità.\\
integrale generale:
	$y(t) = y(0)e^{kt} $con$ c>0$\\


\noindent{\textbf{2° Modello: Verhulst (metà '800)}}\\
\begin{equation}
	y'(t)=ky(t)-hy(t)^2 \quad  \textnormal{con } k,h > 0
\end{equation}

Il modello prende anche in considerazione la competizione per le risorse al crescere della popolazione.\\
\bigskip
\emph{Simulazione numerica per $k=h=1$}

\begin{tikzpicture}
	\begin{axis}[ymin = 0, ymax = 1.5, axis lines = left, height = 4.5cm, width = 8cm, legend pos = south east]

\addplot [
    domain=0:6, 
    samples=100, 
    color=red,
]
{1/(1-(1/3)*e^(-x))};
\addlegendentry{$y(0)=1.5$}
\addplot [
    domain=0:6, 
    samples=100, 
    color=blue,
    ]
    {1/(1+e^(-x))};
\addlegendentry{$y(0)=0.5$}
\addplot [
	domain=0:6, 
	samples=100, 
	color=green,
	]
	{1};

	\end{axis}
\end{tikzpicture}

\newpage % verifica
\textbf{Integrale generale dell'Equazione Logistica}\\
Trovo l'integrale generale risolvendo come Bernoulli
\begin{enumerate}

    \item Soluzioni costanti\hspace{1cm}  $y(t)=0,\hspace{0.5cm}   y(t)=\frac{k}{h}$
    \item Divido per $y^2: \hspace{0.5cm}   \frac{y'(t)}{y^2(t)} = \frac{k}{y(t)}-h$ 
    \item Pongo $z'(t)=\frac{1}{y(t)}=-\frac{k}{y(t)}+h=-kz(t)+h$ ricavo che $z'(t) + kz(t)=h$
    \item $z(t)= e^{-\int k}[\int e^{\int k}h dx+c]$\\\\$=e^{-kt}[h\int e^{kx} dx+c]$\\\\$=e^{-kt}[\frac{h}{k}e^{kt}+c]$\\\\$=\frac{\frac{h}{k}e^{kt}+c}{e^{kt}}$
    \item $y(t)=\frac{1}{z(t)}=\frac{e^{kt}}{\frac{h}{k}e^{kt}+c}=\frac{ke^{kt}}{he^{kt}+kc}$\\ possiamo scrivere $kc=c'$ in quanto costante arbitraria
    
\end{enumerate}

\newpage

\section[EDO 2° ordine lineari]{Equazioni differenziali ordinarie del 2° ordine lineari}{}
\subsection{Teorema di struttura dell'integrale generale di EDO del 2° ordine lineari omogenee}
Siano $a,b,c : I \subseteq \mathbb{R} \to \mathbb{R}$ funzioni continue e $a \neq 0$ in $I$.\\
L'integrale generale dell'eq. omogenea
\begin{equation}
	a(t)y''(t) + b(t)y'(t) + c(t)y(t) = 0
\end{equation}
è uno spazio vettoriale di dimensione 2, cioè le soluzioni sono tutte e sole della forma:
\begin{equation}
	y_0(t) = c_1y_{0_1}+c_2y_{0_2} \quad \textnormal{con } c_1,c_2 \in \mathbb{R}^n
\end{equation}
dove $y_{0_1},y_{0_2}$ sono due soluzioni linearmente indipendenti.\\


\emph{Oss:} Dire che due soluzioni sono linearmente indipendenti significa che non esiste un coefficiente $c$ tale che $c\cdot y_1 = y_2$, ovvero che non sono una multipla dell'altra.\\
\emph{Premesse:}
\begin{enumerate}
\item Spazio vettoriale $V=C^2(I)$
\item $I\subseteq\mathbb{R}$ funzione di 1 variabile $y(t)$
\item $C^2(I) = \{y:I \to \mathbb{R}$, derivabili in $I$ e $y'$ continua in $I\}$
\item $C^2(I) = \{y \in C^1(I)$, derivabili due volte in $I$ con $y''$ continua in $I\}$
\item $C^2(I)$ è uno spazio vettoriale con le operazioni usuali di somma di funzioni e prodotto di funzione per uno scalare.
\end{enumerate}

\begin{dimostrazione}
	

\emph{\textbf{da sapere all'esame}}
\begin{itemize}
\item L'integrale generale dell'omogenea è:\\
		$W = \{y \in V : ay''(t) + by'(t) + cy(t) = 0\}$
\item W è un sottospazio vettoriale di V $\Leftrightarrow$ è chiuso rispetto alla somma e rispetto al prodotto per uno scalare. Questo è vero grazie al principio di sovrapposizione (caso particolare dell'omogenea).
\item Devo dimostrare che W ha dimensione 2.
\begin{enumerate}
	\item[$i ) $] Determinare 2 soluzioni lineari indipendenti dell'equazione $y_{0_1}, y_{0_2}$
	\item[$ii )$] Dimostrare che ogni soluzione $y$ della EDO si scrive come combinazione lineare di $y_{0_1}, y_{0_2}$
	\item [$i )$] Scelgo $y_{0_1}$ soluzione del problema di Cauchy.\\
				$$
				\left\{
				\begin{array}{ll}
					ay''_{0_1}(t) + by'_{0_1}(t) + cy_{0_1}(t) = 0\\
					y_{0_1}(0) = 1\\
					y'_{0_1}(0) = 0
				\end{array} \right.
				$$
				Verifico che $y_{0_1}, y_{0_2}$ sono soluzioni lineari indipendenti. Se per assurdo fossero una multiplo dell'altra\\
				$ y_{0_1}(t) = \lambda y_{0_2}(t) \quad \forall t$\\
				In particolare, per $t=0$ avrei $y_{0_1}(0) = \lambda y_{0_2}(0)$ avrei trovato $1=\lambda\cdot 0$ assurdo.
	\item [$ii )$] Sia $y_0(t)$ soluzione dell'EDO, cerco $c_1,c_2\in \mathbb{R}$ tali che $y_0(t) = c_1y_{0_1}(t) + c_2y_{0_2}(t)$\\
					$ y_0(t) = c_1y_{0_1}(t) + c_2y_{0_2}(t) = c_1$\\
					\medskip
					$ y_0'(t) = c_1y_{0_1}'(t) + c_2y_{0_2}'(t) = c_2$\\
					In conclusione la funzione:\\
					$z(t) = y_0(0)\cdot y_{0_1}(t) + y_0'(0)\cdot y_{0_2}(t)$\\
					risolve lo stesso problema di Cauchy di $y_0(t)$ e quindi, grazie al teorema di esistenza e unicità di Cauchy, coincidono:\\
					$y_0(t) = z(t) \quad \forall t$,\\
					cioè $y_0(t)$ si scrive come combinazione lineare di $y_{0_1}, y_{0_2}$ con coefficienti $c_1=y_0(0)$ e $c_2=y_0'(0)$.\\
\end{enumerate}
\end{itemize}
\end{dimostrazione}
\SectionBreak

\subsection{Struttura dell'integrale generale di EDO del 2° ordine lineari non omogenee}
Siano $a,b,c:\mathbb{R} \to \mathbb{R}$ con $a\neq 0$ in $I$\\
L'integrale generale dell'eq. completa
\begin{equation}
	ay''(t) + by'(t) + cy(t) = f(t)
\end{equation}
è:
\begin{equation}
	y(t) = y_0(t) + y_p(t)
\end{equation}
dove la $y_0(t)$ è l'integrale dell'eq. omogenea, come nel teorema precedente, e la $y_p(t)$ è una soluzione particolare dell'eq. compleata.\\

\emph{Oss:} L'integrale generale di una EDO del secondo ordine lineare non omogenea è quindi uno spazio affine (cioè il translato di uno spazio vettoriale) di dimensione 2.\\
% ripasso gal

\begin{center}
	\textbf{Fine lezione 21/09 c'è una scritta in fondo in rosso che non so cosa sia.}
\end{center}



\newpage
\section{Sistemi differenziali lineari}
Esempio introduttivo $F=ma$
\begin{equation}
	y''(t) = \frac{F}{m}
\end{equation}
Trasformo in un sistema di due equazioni differenziali di primo ordine:\\
$ y_1(t) = y(t)$: posizione e $y_2(t) = y'(t) = y'_1(t)$: velocità.\\
$$ \left\{\begin{array}{lr} y'_1(t)=y_2(t) \quad \quad \textnormal{la velocità è la derivata della posizione}\\ y'_2(t)=\frac{F}{m} \quad \quad \textnormal{l'accelerazione è la derivata della velocità}\end{array}\right. $$
In forma matriciale:
\begin{center}
	\textbf{\emph{E mo come la disegno?\\...}}
	
\end{center}
In forma compatta:
$\underline{y'}(t) = A\underline{y}(t)+\underline{b}(t)$\\
\begin{equation}
	\underline{y'}(t) = \begin{pmatrix} y_1(t) \\ y_2(t) \end{pmatrix} \quad A = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix} \quad \underline{b} =\begin{pmatrix} 0 \\ \frac{F}{m} \end{pmatrix}
\end{equation}

\SectionBreak
Esercizi:

\begin{center}
	\emph{\textbf{Esercizi qua}}
\end{center}

\SectionBreak
\begin{definition}
	\emph{Sistema differenziale lineare} è un sistema di equazioni differenziali di primo ordine con coefficienti costanti, cioè:
	\begin{equation}
		\underline{y'}(t) = A\underline{y}(t)+\underline{b}(t)
	\end{equation}
	dove $A$ è una matrice quadrata di ordine $n$ e $\underline{b}$ è un vettore di dimensione $n$.
\end{definition}
% ripasso gal
\SectionBreak

\subsection{Risultati teorici}
Come si scrive un problema di Cauchy per un sistema?\\
\emph{Esempio:} $y''(t)-2y'(t)=t$ con $y(0)=y_0$ e $y'(0)=v_0$\\
Trasformo la EDO in sistema
\begin{equation}
	\left\{
	\begin{array}{ll}
		y'_1(t) = y_2(t)\\
		y'_2(t) = 2y_2(t)+t
	\end{array}
	\right.
\end{equation}
Un problema di Cauchy è $$ \begin{array}{ll} y_1(t_0) = y_0 \\ y_2(t_0)=v_0  \end{array} \quad \quad \underline{y}(t_0) = \begin{pmatrix} y_0 \\ v_0 \end{pmatrix}$$\\

\begin{definition}
	Dato $\underline{y}'(t)=A\underline{y}(t)+\underline{b}(t)$ con $A$ matrice quadrata di ordine $n$ e $\underline{b}$ vettore di dimensione $n$\\
	chiamiamo problema di Cauchy: $$ \left\{ \begin{array}{ll} \underline{y}'(t) = A \cdot y(t) + \underline{b}(t) \\ \underline{y}(t_0) = \underline{y}_0  \end{array} \right.$$
\end{definition}

\begin{center}
	\emph{\textbf{Esempi}}
\end{center}

\SectionBreak

\begin{center}
	\emph{\textbf{C'è una pagina che non so se è spiegazione o esercizi, ci sono parti scritte in LaTeX e altre a mano.\\ * \\ * \\Prosegue poi con i sistemi omogenei.}}
\end{center}

\SectionBreak

\section{Sistemi non omogenei}
\subsection{Struttura dell'int. gen. dei sistemi non omogenei}
\begin{center}
	\emph{\textbf{Manca la definizione.}}
\end{center}

Praticamente, per risolvere un sistema non omogeneo:
\begin{enumerate}
	\item Si risolve il sistema omogeneo associato. Cioè determino una matrice Wronskiana $W(t) = \left[y_{0_1}(t)\ldots y_{0_n}(t)\right]$\\
			Integrale generale: $ \underline{y}(t) = W(t)\cdot \underline{c}, \quad \underline{c}\in\mathbb{R}^n$
	\item Due possibilità: \begin{itemize}
		\item cerco una soluzione particolare con il metodo di somiglianza \\ $\underline{y}(t) = \underline{y}_0(t) + \underline{y}_p(t) = W(t) \cdot \underline{c} + \underline{y}_p(t)$
		\item uso $W(t)$ per trovare direttamente l'integrale generale tramite la formula:\\$ \underline{y}(t) = W(t) \left(\int\left[W(\tau)\right]^{-1}\cdot \underline{b}(\tau)\right) = W(t) \int \left[W(\tau)\right]^{-1} \cdot \underline{b}(\tau) d\tau + W(t)\cdot \underline{c}$
		Confronto le due soluzioni.\\
		Nella prima ho $W(t)\cdot\underline{c}$ e anche nella seconda, ed è l'integrale generale dell'omogenea.\\
		Quindi $y_p(t) = \underline{y}(t) - W(t)\int \left[W(\tau)\right]^{-1} \cdot \underline{b}(\tau) d\tau$ perché è ciò che resta da uguagliare.\\
		In particolare, se $A$ è diagonalizzabile reale, allora una matrice Wronskiana è $W(t) = e^{At}$\\
		$\underline{y}(t) = e^{At} \left[\int e^{-At}\cdot \underline{b}(\tau) d\tau + \underline{c}\right] $\\
		\emph{Osservazioni da aggiungere.}\\
		\emph{Esempio da aggiungere.}	
	\end{itemize}



\end{enumerate}

\chapter{Serie di funzioni}


\section{Generalità sulle serie di funzioni}
Esempio: Sviluppi di Taylor:
\begin{equation}
e^x = \sum_{n=0}^\infty \frac{x^n}{n!} = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \ldots
\end{equation}
\begin{equation}
	\frac{1}{1-x} = \sum_{n=0}^\infty x^n = 1 + x + x^2 + x^3 + \ldots
\end{equation}

\begin{definition}
	\ \\
	Date delle funzioni $f: J\subseteq\mathbb{R}\to\mathbb{R}$ \quad $n=(0,1,2,\ldots)$
	\begin{itemize}
		\item La serie di funzioni a termine generale $f_n(x)$ è la successione delle somme parziali \\ $S_n(x) = \sum_{k=0}^n f_k(x)$\\
				\emph{Oss: }Fissato $\overline{x}\in J$ si tratta di una serie numerica
		\item La serie di funzioni converge puntualmente (o semplicemente) nel punto $\overline{x}_0\in J$ se la serie numerica di termini generale $f_n(\overline{x})$ è convergente, cioè se esiste finito il limite: \\ $\lim_{n\to\infty} S_n(\overline{x}) = \sum_{k=0}^\infty f_k(\overline{x})$
		\item Chiamiamo insieme di convergenza puntuale (o semplice) l'insieme $E \subseteq J$ dei punti $\overline{x}_0$ in cui la serie di funzioni converge puntualmente.\\ Nell'insieme $E$ risulta così definita una nuova funzione, detta somma della serie, che si indica con il simbolo: \\ $f(x) = \sum_{k=0}^\infty f_k(x) \quad (x \in E)$\\ Significa: \\ $f(x) = \lim_{n\to\infty} S_k(x) \quad (x \in E)$
		\item La serie di funzioni converge assolutamente in $\overline{x} \in J$ se la serie numerica di termine generale $f_n(\overline{x})$ converge.\\ \emph{Oss:} la convergenza assoluta...
	\end{itemize}
\end{definition}

\emph{Esempio fondamentale: Serie geometrica.}\\
$\sum_{n=0}^\infty x^n$\\
\emph{Oss.}Servirà per la serie di potenze: $\sum_{n=0}^\infty a_n(x-x_0)^n$\\
insieme convergenza puntuale $E = (-1,1)= \left\{ \left\lvert x\right\rvert <1\right\}$\\
Per $x \leq  -1$ è indeterminata\\
per $x \geq 1$ è divergente\\
per ... 
\bigskip\\
\textbf{Serie di Riemann}\\
$\sum_{n=0}^\infty \frac{1}{n^x} \quad \quad f_n(x)=\frac{1}{n^x}=\left(\frac{1}{n}\right)^x$
L'insieme di convergenza puntuale è:\\
$E=(1,\infty) = \left\{ x>1 \right\}$\\
La convergenza è anche assoluta in $E$ perché per $x\in E \quad \quad \left\lvert f_n(x)\right\rvert = f_n(x)$
\bigskip\\
Se $x=1$ è la serie armonica $\sum_{n=1}^\infty \frac{1}{n}$ che diverge.\\
\SectionBreak
\medskip
\emph{Problema:} se le funzioni $f_n$ sono continue, anche $f$ lo è? \textbf{Segue...}

\subsection{Convergenza totale di una serie di funzioni}
\emph{\textbf{copiare appunti della prof, formule e grafici}}\\
\begin{definition}
	Importante\\
	Diciamo che la serie di termine generale $f_n(x), x\in J$ converge totale in $I \in J$ se esiste una successione numerica $a_n$ tale che: 
	\begin{enumerate}
		\item[$i )$] $\lim_{n\to\infty} \left\lvert f_n(x) - a_n\right\rvert = 0 \quad \forall x \in I \quad \forall n$\\
		\item[$ii )$] $\sum_{n=0}^\infty a_n < \infty$
	\end{enumerate}
\end{definition}
\emph{Oss:} \begin{itemize}
	\item La nozione di convergenza totale riguarda un intervallo, mai un punto.
	\item La convergenta totale in $I$ implica la convergenza assoluta (quindi anche puntuale) in ogni punto di $I$.
	\item \textbf{Attenzione:} non vale il viceversa: se una serie converge assolutamente in ogni punto di $I$ non è detto che converga totalmente in $I$.
\end{itemize}




\section*{inizio lezione 05/10/2022}
\emph{Oss:} Se una serie di funzioni converge totalmente in $I$ allora converge totalmente in ogni sottoinsieme di $I$.\\
\textbf{Esercizio:} Studiare la convergenza totale della serie:\\
\begin{equation}
	\sum_{n=0}^\infty \frac{\sin{(nx)}}{n^3}
\end{equation}

\textbf{Esercizio:} Studiare la convergenza totale della serie geometrica:\\
\begin{equation}
	\sum_{n=0}^\infty x^n
\end{equation}

\textbf{\emph{Appunti su convergenza semplice, assoluta, puntuale, e totale}\\}
\subsection{Conseguenze della convergenza totale}
\begin{thm} Continuità della somma\\
	Siano $f_n(x)$ funzioni definite su un intervallo $I\subseteq \mathbb{R}$. Se:
	\begin{enumerate}
		\item[$i)$] $f_n(x)$ è continua in $I$ per ogni $n$
		\item[$ii)$] la serie di funzioni $\sum_{n=0}^\infty f_n(x)$ converge totalmente in $I$
	\end{enumerate}
	Allora la funzione somma $f(x) = \sum_{n=0}^\infty f_n(x)$ è continua in $I$.\\
\emph{Oss:} in particolare, $f$ è integrabile in ogni sottoinsieme chiuso e limitato $\left[c,d\right] \subseteq I$
\end{thm}

\begin{thm} Integrabilità termine a termine\\
	Nelle stesse ipotesi del teorema precedente $f$ è integrabile in ogni $\left[c,d\right] \subseteq I$ chiuso e limitato e inoltre:
	\begin{equation}
		\int_{c}^{d} f(x) dx = \int_{c}^{d} \left(\sum_{n=0}^\infty \int_{c}^{d} f_n(x)\right)  dx = \sum_{n=0}^\infty \left(\int_{c}^{d} f_n(x) dx\right) 
	\end{equation}
	Quindi posso scambiare il simbolo di serie e quello di integrale.
\end{thm}

\emph{Oss:} Se $f(n)$ derivabili in $I$ e $\sum^\infty f_n'$ converge totalmente in $I$ allora $\left(\sum^\infty f_n(x)\right)' = \sum^\infty f_n'(x)$





\section{serie di potenze}
\begin{definition}
	Una serie di potenze è una serie di funzioni della forma:
	\begin{equation}
		\sum_{n=0}^\infty a_n \left(x-x_0\right)^n = a_0+a_1(x-x_0)+a_2(x-x_0)^2+\dots 
	\end{equation}
	Con $a_n \in \mathbb{R}$ coefficienti della serie\\
	$x_0 \in \mathbb{R}$ centro della serie
\end{definition}
\emph{Convenzione:} se $x=x_0$ e $n=0$ $\left(x_0-x_0\right)^0 = 1$. Quindi, per $x=x_0$ la serie di potenze diventa:
\begin{equation}
	\sum_{n=0}^\infty a_n \left(x_0-x_0\right)^n = a_0+a_1(x_0-x_0)+a_2(x_0-x_0)^2+\dots = a_0
\end{equation}
Cioè tutte le serie di potenze convergono almeno nel loro centro $x=x_0$.\\

\section*{inizio lezione 07/10/2022}
\emph{ripasso convergenza totale}\\
\emph{integra}
\begin{itemize}
	

	\item vedremo in dettaglio che la serie esponenziale $e^x=\sum_{n=0}^\infty \frac{x^n}{n!} \quad a_n = \frac{1}{n!}$ ha come insieme di convergenza $\mathbb{R}$\\
			la serie $metti serie$ converge rapidamente. Criterio del rapporto $l=lim_{n\to\infty} \frac{a_{n+1}}{a_n} = \lim{n\to\infty}\frac{1}{n+1}=0<1$\\
	\item la serie logaritmica $ln(1+x)=\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n}x^n \quad a_n = \frac{(-1)^{n+1}}{n}$ ha come insieme di convergenza $E=(-1,1)$\\
\end{itemize}

\begin{thm}
	Raggio di convergenza\\
	La serie di potenze reale $\sum_{n=0}^\infty a_n \left(x-x_0\right)^n$ si verifica sempre una delle tre:
	\begin{enumerate}
		\item raggio di convergenza nullo: la serie converge solo nel suo centro $x=x_0$
		\item raggio di convergenza infinito: la serie converge assolutamente  $\forall x\in\mathbb{R}$
		\item raggio di convergenza $0<R<+\infty$: esiste $R>0$ tale che:
																\begin{itemize}
																	\item la serie converge assolutamente $\forall x$ tale che $|x-x_0|<R$
																	\item la serie non converge per $|x-x_0|>R$
																\end{itemize}
	\end{enumerate}
	\emph{Oss:} in $|x_0+R|$ e $|x_0-R|$ potrebbe convergere o no, va studiato a parte in ogni esercizio.
\end{thm}

\begin{thm}
	Calcolo del raggio di convergenza\\
	Data una serie di potenze reale $\sum_{n=0}^\infty a_n \left(x-x_0\right)^n$\\
	\begin{enumerate}
		\item[$i)$] se il limite esiste.\\$R=\lim_{n\to\infty} \left\lvert \frac{a_n}{a_{n+1}}\right\rvert = \lim_{n\to\infty} \frac{|a_{n+1}|}{|a_n|}$\\allora la serie di potenze ha raggio di convergenza $R$.
		\item[$ii)$] se esiste il limite $R=\lim_{n\to\infty} \frac{1}{\sqrt[n]{\left\lvert a_n\right\rvert }}$ allora la serie di potenze ha raggio di convergenza $R$.
	\end{enumerate}
\end{thm}

\begin{dimostrazione} 
	\emph{\textbf{da sapere all'esame}}\\
	% \emph{teorema:} se $a_n \in \mathbb{R}$ e $a_n \to 0$ allora $\lim_{n\to\infty} \frac{a_n}{a_{n+1}} = 0$\\
	La serie di potenze converge assolutamente nel punto $\overline{x} \in \mathbb{R}$ se e solo se\\
	$\sum_{n=0}^\infty \left\lvert a_n\right\rvert  \left\lvert \overline{x} -x_0\right\rvert ^n$ converge.\\
	\begin{itemize}
		\item se il criterio del rapporto è applicabile, ho convergenze se e solo se\\$\lim_{n\to\infty} \frac{b_{n+1}}{b_n} < 1\Leftrightarrow \left\lvert \overline{x} -x_0 \right\rvert < \frac{1}{\lim_{n\to\infty} \frac{a_{n+1}}{a_n}} = \lim_{n\to\infty} \frac{\left\lvert a_n\right\rvert }{\left\lvert a_{n+1}\right\rvert } = R$
		\item se il criterio della radice è applicabile, la serie converge se e solo se\\$\lim_{n\to\infty} \sqrt[n]{b_n}<1$ \textbf{manca roba}
	\end{itemize}
\end{dimostrazione}

\begin{thm} % Convergenza totale per serie di potenze reali
	Data una serie di potenze avente raggio di convergenza $0<R\leq +\infty$ si ha:
	\begin{enumerate}
		\item[$i)$] se $R=+\infty$ la serie converge totalmente in ogni intervallo chiuso e limitato $\left[c,d\right] $
		\item[$ii)$] se $0<R<+\infty$ la serie converge totalmente in ogni intervallo chiuso  $\left[c,d\right] \subset \left(x_0-R,x_0+R\right)$
	\end{enumerate}
\end{thm}


\begin{thm}
	Data una serie di potenze reale $\sum_{n=0}^\infty a_n \left(x-x_0\right)^n$ avente raggio di convergenza $0<R<+\infty$, per ogni $x\in\left(x_0-R,x_0+R\right)$ vale la formula di integrazione termine a termine:
	\begin{equation}
		\int_{x_0}^{x} \sum_{n=0}^\infty a_n \left(t-x_0\right)^n dt = \sum_{n=0}^\infty \frac{a_n}{n+1} \left(x-x_0\right)^{n+1}
	\end{equation}
	La serie di potenze integrata $\sum_{n=0}^\infty \frac{a_n}{n+1} \left(x-x_0\right)^{n+1}$ converge per $x\in\left(x_0-R,x_0+R\right)$.
\end{thm}

\emph{Osservazione Importante:} Se la serie di potenze iniziale converge in $x_0-R$ (o $x_0+R$) posso integrare termine a termine fino a $x_0-R$ (o $x_0+R$).\\

\begin{center}
	$\cdots$
\end{center}


\begin{thm}
	Derivabilità termine a termine per serie di potenze reali\\
	Data una serie di potenze reale $\sum_{n=0}^\infty a_n \left(x-x_0\right)^n$ avente raggio di convergenza $0<R<+\infty$, per ogni $x\in\left(x_0-R,x_0+R\right)$ vale la formula di derivazione termine a termine.
	\begin{equation}
		\left(\sum_{n=0}^\infty a_n \left(x-x_0\right)^n\right)'  = \sum_{n=1}^\infty  a_n n \left(x-x_0\right)^{n-1}
	\end{equation}
	e la serie di potenze derivata ha raggio di convergenza $R$.\\
	Si può iterare per ottenere serie derivate di ogni ordine, tutte con raggio di convergenza $R$.

\end{thm}

\noindent\emph{Conseguenza:} la somma di una serie di potenze è derivabile ad ogni ordine.\\
\emph{Oss:} la serie derivata ha ancora raggio di convergenza $R$, ma il comportamente ai bordi $x_0\pm R$ può variare rispetto alla serie inerziale.\\

\section{Lezione del 12/10/2022}
\begin{definition}
	Una funzione di una variabile reale $f$ è detta analitica reale nell'intevallo non vuoto $(a,b)$ se è somma di una serie di potenze in $(a,b)$, cioè se esistono $x_0\in (a,b), a_n \in \mathbb{R}$ e tale che:\\
	$f(x) = \sum_{n=0}^\infty a_n \left(x-x_0\right)^n$ per ogni $x\in (a,b)$.
\end{definition}

Se $f$ è analitica in $(a,b)$:
\begin{itemize}
	\item Qual è la regolarità minima di $f$?\\
		\emph{Risposta:} $f$ derivabile ad ogni ordine in $(a,b)$.
	\item Chi sono i coefficienti $a_n$?\\
		\emph{Risposta:} $f(x_0) = \sum_{n=0}^\infty a_n \left(x-x_0\right)^n = a_0$\\
		$f'(x_0) = \sum_{n=1}^\infty a_n n \left(x-x_0\right)^{n-1} = a_1$\\
		$f''(x_0) = \sum_{n=2}^\infty a_n n(n-1) \left(x-x_0\right)^{n-2} = 2a_2$\\
		$a_n = \frac{f^{(n)}(x_0)}{n!}$
\end{itemize}

\begin{thm}
	\emph{Funzioni analitiche reali}\\
	Se $f$ è analitica reale nell'intervallo non vuoto $(a,b)$ allora è derivabile ad ogni ordine in $(a,b)$ e per ogni $x_0\in (a,b)$ è sviluppabile in serie di Taylor. Cioè:
	\begin{equation}
		f(x) = \sum_{n=0}^\infty \frac{f^{(n)}(x_0)}{n!} \left(x-x_0\right)^n \quad x\in (a,b)
	\end{equation}
	Inoltre, detto $R$ il raggio di convergenza della serie, l'identità è verificata per ogni $x\in (x_0-R,x_0+R)$.
\end{thm}

\subsection*{Serie esponenziale}
La funzione $e^x$ è analitica in $\mathbb{R}$ (non dimostriamo)\\
La sua serie di Taylor con $x_0=0$ è:
\begin{equation}
	e^x = \sum_{n=0}^\infty \frac{x^n}{n!} = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots
\end{equation}
Il raggio di convergenza è $R=+\infty$\\


\emph{oss:} Non tutte le funzioni derivabili ad ogni ordine in un intervallo sono analitiche in quell'intervallo. [es. BCFTV II.4]

\newpage
\section{serie di Fourier}
Segnale sonoro periodico:
\begin{equation}
	f(x)=3\cos(x)-\sin(2x)-\cos(10x)
\end{equation}

% grafico della funzione
\begin{tikzpicture}
\begin{axis}
\addplot[domain=-10:10,samples=1000,smooth] {3*cos(x)-sin(2*x)-cos(10*x)};
\end{axis}
\end{tikzpicture}

Per trasmettere il segnale basta comunicare i coefficienti:\\
%tabella dei coefficienti

\emph{integra}
\section*{Lezione del 14/10/2022}

\emph{Funzioni periodiche, polinomi e serie trigonometriche}\\
Ricordiamo che $f:\mathbb{R}\to\mathbb{R}$ è periodica di periodo $T$ se  $f(x)=f(x+T)$ per ogni $x\in\mathbb{R}$.\\
\emph{Oss:} 
\begin{itemize}
	\item Non ci sono ipotesi di regolarità su $f$.
	\item Se $f$ è periodica di periodo $T$ allora è anche periodica di periodo $2T, 3T, 4T \cdots$
	\item Se $f$ è periodica di periodo $T$ ed è pari (rispettivamente dispari) sul suo periodo, allora è anche pari (rispettivamente dispari) su $\mathbb{R}$.
\end{itemize}
% ripasso funzioni pari e dispari

\begin{definition}
	Chiamiamo armoniche $n$-esime le funzioni:
	\begin{equation}
		\cos(nx), \sin(nx)\quad \quad x\in\mathbb{R} n=1,2,3,\cdots
	\end{equation}
	Ogni armonica $n$-esima è periodica di periodo $\frac{2\pi}{n}$.
\end{definition}
\emph{Oss:} Tutte le armoniche $n$-esime sono anche periodiche di periodo $2\pi$\\
Caso speciale: $n=0$ la funzione costante 1.

\subsection{Formule di ortogonalità} % è una sottosezione? todo

% 0 se n!=k. pi se n=k!=0
\begin{equation}
	\int_{-\pi}^\pi \cos(nx)\cos(kx)dx =
		\begin{cases*}
			0 	& se  $n\neq k$\\
			\pi & se  $n=k\neq 0$
		\end{cases*}
\end{equation}
\begin{equation}
	\int_{-\pi}^\pi \sin(nx)\sin(kx)dx =
		\begin{cases*}
			0 	& se $n\neq k$\\
			\pi & se $ n=k\neq 0$
		\end{cases*}
\end{equation}
\begin{equation}
	\int_{-\pi}^\pi \cos(nx)\sin(kx)dx = 0
\end{equation}


\begin{definition}
	Un polinomio trigonometrico di ordine n è una combinazione lineare di  armoniche $n$-esime con $n=0,1,2,\cdots,m$, cioè:
	\begin{equation}
		a_0 + \sum_{n=1}^m \left(a_n \cos(nx) + b_n \sin(nx)\right)
		a_0, a_n, b_n \in \mathbb{R} \text{ e } x\in\mathbb{R}
	\end{equation}
\end{definition}
\emph{Oss:}
\begin{itemize}
	\item un polinomio trigonometrico è periodico di periodo $2\pi$
	\item la somma, differenza, prodotto di due polinomi trigonometrici è ancora un polinomio trigonometrico.
\end{itemize}

\begin{definition}
	Una serie trigonometrica è:
	\begin{equation}
		\sum_{n=0}^\infty \left(a_n \cos(nx) + b_n \sin(nx)\right)
	\end{equation}
	Con $a_0,a_n,b_n\in\mathbb{R}$
\end{definition}

Ogni polinomio trigonometrico è $2\pi$-periodico, quindi la somma di una serie trigonometrica è $2\pi$-periodica.\\
Per questo motivo supporremo sempre che la funzione che vogliamo decomporre sia $2\pi$-periodica.\\

% todo criterio di leibnitz ricordiamo

Derivando termine a termine una serie trigonometrica si può perdere regolarità. Questo differenzia le serie trigonometriche dalle serie di potenze, che sono sempre derivabili ad ogni ordine dentro il raggio di convergenza.

% todo integra la parte in blu appunti prof. probabilmente abbastanza superfluo

\begin{thm}
	Convergenza totale di una serie trigonometrica\\
	Data la serie trigonometrica $a_0 + \sum_{n=1}^\infty \left(a_n \cos(nx) + b_n \sin(nx)\right)$
	\begin{enumerate}
		\item[$i)$] Se $\sum_{n=1}^\infty \left(|a_n| + |b_n|\right) <+\infty$ allora la serie converge totalmente in $\mathbb{R}$.\\
				In particolare, la funzione somma è continua in $\mathbb{R}$ e posso integrare termine a termine in ogni sottoinsieme limitato.
		\item[$ii)$] Se $\sum_{n=1}^\infty n\cdot\left(|a_n| + |b_n|\right) =+\infty$ allora la funzione somma è derivabile in $\mathbb{R}$ e posso derivare termine a termine.
	\end{enumerate}
\end{thm}
\emph{Oss:} ci interesseranno anche le serie di Fourier che non convergono totalmente in $\mathbb{R}$, cioè tali che $\sum_{n=1}^\infty \left(|a_n| + |b_n|\right) =+\infty$
Infatti se il segnale periodico $f(x)$ che voglio comporre non è continuo su $\mathbb{R}$ allora la convergenza della serie trigonometrica non può essere totale in $\mathbb{R}$.

\subsection{Costruzione della serie di Fourier di una funzione periodica}
\begin{thm}
	Calcolo dei coefficienti di Fourier\\
	Sia $f:\mathbb{R}\to\mathbb{R}, 2\pi$ una funzione periodica e somma di una serie trigonometrica
	\begin{equation}
		f(x) = a_0 + \sum_{n=1}^\infty \left(a_n \cos(nx) + b_n \sin(nx)\right)
	\end{equation}
	Supponiamo inoltre di poter integrare termine a termine. Allora:
	\begin{equation}
		a_0 = \frac{1}{2\pi}\int_{-\pi}^\pi f(x)dx
	\end{equation}
	\begin{equation}
		a_n = \frac{1}{\pi}\int_{-\pi}^\pi f(x)\cos(nx)dx
	\end{equation}
	\begin{equation}
		b_n = \frac{1}{\pi}\int_{-\pi}^\pi f(x)\sin(nx)dx
	\end{equation}
\end{thm}

\begin{dimostrazione}
	\emph{\textbf{da sapere all'esame}}
	\begin{itemize}
		\item Integro $f$ in $\left(-\pi,\pi\right)$, uso integrazione temrine a termine e formula di ortogonalità:
			\begin{equation}
				\int_{-\pi}^\pi f(x)dx = \int_{-\pi}^\pi \left(a_0 + \sum_{n=1}^\infty \left(a_n \cos(nx) + b_n \sin(nx)\right)\right)dx
			\end{equation}
			\begin{equation}
				= \int_{-\pi}^\pi a_0dx + \sum_{n=1}^\infty a_n \int_{-\pi}^\pi \cos(nx)dx + \sum_{n=1}^\infty b_n \int_{-\pi}^\pi  \sin(nx)dx
			\end{equation}
			\begin{equation}
				a_0 = \int_{-\pi}^\pi 1dx = 2\pi a_0
			\end{equation}
		\item Per trovare $a_n$, moltiplico $f$ per $\cos{nx}$, integro in $\left(-\pi,\pi\right)$, uso l'integrabilità termine a termine  ele formule di ortogonalità:
			\begin{equation}
				\int_{-\pi}^\pi f(x)\cos(nx)dx = \int_{-\pi}^\pi \left(a_0 + \sum_{k=1}^\infty \left(a_k \cos(kx) + b_k \sin(kx)\right)\right)\cos(nx)dx
			\end{equation}
			\begin{equation}
				= a_0 \int_{-\pi}^\pi \cos(nx)dx + \sum_{k=1}^\infty a_k \int_{-\pi}^\pi \cos(kx)\cos(nx)dx + \sum_{k=1}^\infty b_k \int_{-\pi}^\pi \sin(kx)\cos(nx)dx
			\end{equation}
			\begin{equation}
				= a_0 \int_{-\pi}^\pi \cos^2(nx)dx = a_n\pi
			\end{equation}
		\item Per trovare $b_n$, moltiplico per $\sin{(nx)}$
	\end{itemize}
\end{dimostrazione}

Piano di lavoro: data $f:\mathbb{R}\to\mathbb{R}$, $2\pi$-periodica integrabile in $\left[-\pi,\pi\right]$:
\begin{enumerate}
	\item Calcolo i coefficienti $a_0, a_n, b_n$ con le formule trovate nel teorema precedente
	\item Con questi coefficienti costruisco la serie trigonometrica
	\item Studio la convergenza della serie trigonometrica e, in particolare cerco di stabilire se la somma coincide con $f$ in ogni punto
\end{enumerate}

\begin{definition}
	Sia $f:\mathbb{R}\to\mathbb{R}$, $2\pi$-periodica, integrabile in $\left[-\pi,\pi\right]$.
	\begin{itemize}
		\item Chiamiamo coefficenti di Fourier di $f$ i valori $a_0, a_n, b_n$ definiti nel teorema precedente
		\item polinomio di Fourier di $f$ di ordine $m$ il polinomio trigonometrico
			\begin{equation}
				F_m(x) = a_0 + \sum_{n=1}^m \left(a_n \cos(nx) + b_n \sin(nx)\right)
			\end{equation}
		\item Serie di Fourier di $f$ la serie trigonometrica
			\begin{equation}
				F(x) = \sum_{n=1}^\infty \left(a_n \cos(nx) + b_n \sin(nx)\right) = \lim_{m\to\infty} F_m(x)
			\end{equation}
	\end{itemize}
\end{definition}

\emph{\textbf{Importantissimo} per gli esercizi:}
\begin{itemize}
	\item se $f$ è pari, si sviluppa in soli coseni, cioè $b_n=0$ per ogni $n$.
	\item se $f$ è dispari, si sviluppa in soli seni, cioè $a_n=0$ per ogni $n$.
\end{itemize}

\section*{Lezione del 19/10/2022}

Esempio: dente di sega\\
$f(x) = x$\\
per $x \in (-\pi,\pi]$
Essendo $f$ dispari:
\begin{itemize}
	\item si sviluppa in soli seni, cioè $a_0=a_n=0 \quad \forall n$
	\item $b_n = \frac{1}{\pi} \int_{-\pi}^\pi f(x) \sin(nx)dx = \frac{2}{\pi} \int_{0}^\pi f(x) \sin{nx} = -2\frac{(-1)^n}{n}$
\end{itemize}
La serie di Fourier di $f$ è:
\begin{equation}
	-2\sum_{n=1}^\infty \frac{(-1)^n}{n} \sin(nx)
\end{equation}

\SectionBreak
\vspace*{0.5cm} % fix todo
Esempio: Tenda\\
$f:\mathbb{R}\to\mathbb{R}$, $2\pi$-periodica e\\
$f(x) = (x-\pi)^2$ per $x \in (0,2\pi]$\\
$f$ pari, quindi:
\begin{itemize}
	\item $b_n = 0 \quad \forall n$
	\item $a_n = \frac{2}{\pi} \int_{0}^\pi f(x) \cos{nx} dx = \frac{2}{\pi} \int_{0}^\pi (x-\pi)^2 \cos{nx} dx$
\end{itemize}
Quindi:
\begin{equation}
	a_0 = \frac{1}{2\pi} \int_{0}^\pi (x-\pi)^2 dx = \frac{\pi^2}{3} 
\end{equation}

\begin{equation}
	a_n = 
\end{equation}

\subsection{Convergenza della seride di Fourier}
Data $f:\mathbb{R}\to\mathbb{R}$, $2\pi$-periodica, integrabile in $\left[-\pi,\pi\right]$:
\begin{definition}
	Data $f:[-\pi,\pi]\to\mathbb{R}$. Diciamo che $f$ è regolare a tratti in $[-\pi,\pi]$ se esiste un numero finito di punti $x_0, x_1, \cdots, x_n$ in $[-\pi,\pi]$ tali che
	$f$ e derivabile in $(x_i,x_{i+1})\quad \forall i=0,1,\cdots,n-1$ ed esistono finiti i limiti:
	\begin{equation}
		\lim_{x\to x_i^-} f'(x) \quad \forall i=0,1,\cdots,n-1
	\end{equation}
	\begin{equation}
		\lim_{x\to x_i^+} f'(x) \quad \forall i=0,1,\cdots,n-1
	\end{equation}
\end{definition}

%todo disegno
%todo oggetti non verificabili (cuspide e asintoto verticale)

\emph{Oss:} Se $f$ è periodica e regolare a tratti in $[-\pi,\pi]$, allora:
\begin{itemize}
	\item $f$ è regolare a tratti in qualunque intervallo limitato.
	\item Si avrà anche che $f$ è continua in $(x_i,x_{i+1})\quad \forall i=0,1,\cdots,n-1$. ed esistono finiti i limiti:
	\begin{equation}
		\lim_{x\to x_i^-} f(x) \quad \forall i=0,1,\cdots,n-1
	\end{equation}
	\begin{equation}
		\lim_{x\to x_i^+} f(x) \quad \forall i=0,1,\cdots,n-1
	\end{equation}
	\item $f$ è integrabile su qualunque intervallo limitato.
	\item \textbf{Facoltativo:} BCFTV, esercizio $II.12$. La sua serie di Fourier è integrabile termine a termine.
\end{itemize}

\begin{thm} Della convergenza puntuale delle serie di Fourier\\
	Sia $f:\mathbb{R}\to\mathbb{R}$, $2\pi$-periodica, regolare a tratti in $[-\pi,\pi]$.\\
	Allora la serie di Fourier di $f$ converge puntualmente $\forall \mathbb{R}$ e inoltre
	\begin{equation}
		\lim_{m\to+\infty} F_m(x) = \frac{1}{2} \left[ \lim_{s\to x^+} f(s) + \lim_{s\to x^-} f(s) \right] 
	\end{equation}

Parafrasando: la serie di F converge puntualmente alla media tra $f(x^+)$ e $f(x^-)$.\\
In particolare:
\begin{equation}
	f \textnormal{continua in } x \Longrightarrow \lim_{m\to+\infty} F_m(x) = f(x)
\end{equation}
\end{thm}

\begin{thm} Convergenza totale della serie di Fourier\\
	Sia $f:\mathbb{R}\to\mathbb{R}$, $2\pi$-periodica, regolare a tratti in $[-\pi,\pi]$.\\
	Se inoltre $f$ è continua in tutto $\mathbb{R}$, allora la serie di Fourier di $f$ converge totalmente a $f$ in tutto $\mathbb{R}$.
\end{thm}

% verifica gli esempi di prima (tenda e dente di sega) ¿todo?


\section{Lezione del 21/10/2022}
Ripasso\\
tde 16/02/2021

% funzione a tratti
\begin{equation}
	f(x) = \begin{cases}
		\pi-x & x \in (0,\pi] \\
		0 & x = 0
	\end{cases}
\end{equation}
f regolare a tratti, quindi al serie di Fourier converge $\forall x$\\
Funzione somma $S(x) = \lim_{x\to+\infty} F_m(x)$\\
Se $f$ è continua in $x$, allora $S(x) = f(x)$\\
Nei punti dove $f$ è discontinua, cioè $x=2k\pi$,\\
\begin{equation}
	S(x)= \frac{1}{2} \left( \lim_{s\to x^+} f(s) + \lim_{s\to x^-} f(s) \right) = 0 = f(x)
\end{equation}
Conclusione: $S(x) = f(x)$ $\forall x$\\
Riguardo la convergenza totale:\\
% todo aggiungi roba qua

In ogni intervallo dove $S$ è discontinua, la convergenza non può essere totale\\

\SectionBreak

\begin{thm} Convergenza in media quadratica\\
	Sia $f:\mathbb{R}\to\mathbb{R}$, $2\pi$-periodica, regolare a tratti in $[-\pi,\pi]$.\\
	Allora:
	\begin{equation}
		\lim_{m\to+\infty} \int_{-\pi}^\pi \left(F_m(x)-f(x)\right)^2 dx = 0 
	\end{equation}
\end{thm}
Spiegazione: si può dimostrare che la convergenza media quadratica implica:
\begin{equation}
	\lim_{m\to+\infty} \int_{-\pi}^\pi F_m(x)^2 dx = \int_{-\pi}^\pi f(x)^2 dx
\end{equation}
L'area sottesa al grafico di $F_m^2$ converge all'area sottesa al grafico di $f^2$ (per $m\to+\infty$)

\end{document}